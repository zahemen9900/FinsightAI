  0%|                                                                                                                                            | 0/244 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
/home/zahemen/miniconda3/envs/transformer_LM/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  return fn(*args, **kwargs)
 41%|███████████████████████████████████████████████████▋                                                                          | 100/244 [1:04:56<1:37:52, 40.78s/it]/home/zahemen/miniconda3/envs/transformer_LM/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
{'loss': 18.8494, 'grad_norm': 1.245650053024292, 'learning_rate': 0.00018135593220338985, 'epoch': 0.25}
{'loss': 16.2601, 'grad_norm': 0.43849581480026245, 'learning_rate': 0.00015593220338983051, 'epoch': 0.49}
{'loss': 14.6903, 'grad_norm': 0.49917683005332947, 'learning_rate': 0.0001305084745762712, 'epoch': 0.74}
  return fn(*args, **kwargs)                                                                                                                                             
{'eval_loss': 1.7640198469161987, 'eval_runtime': 618.7159, 'eval_samples_per_second': 1.356, 'eval_steps_per_second': 0.679, 'epoch': 0.82}
 82%|████████████████████████████████████████████████████████████████████████████████████████████████████████▉                       | 200/244 [2:03:53<19:29, 26.57s/it]/home/zahemen/miniconda3/envs/transformer_LM/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
{'loss': 14.333, 'grad_norm': 0.8202627897262573, 'learning_rate': 0.00010508474576271188, 'epoch': 0.98}
{'loss': 13.46, 'grad_norm': 0.607562780380249, 'learning_rate': 7.966101694915254e-05, 'epoch': 1.22}
{'loss': 13.2483, 'grad_norm': 0.646153450012207, 'learning_rate': 5.423728813559322e-05, 'epoch': 1.47}
  return fn(*args, **kwargs)                                                                                                                                             
{'eval_loss': 1.7047958374023438, 'eval_runtime': 614.1763, 'eval_samples_per_second': 1.366, 'eval_steps_per_second': 0.684, 'epoch': 1.63}
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 244/244 [2:27:28<00:00, 36.27s/it]
{'loss': 14.1184, 'grad_norm': 0.5325697660446167, 'learning_rate': 2.88135593220339e-05, 'epoch': 1.71}
{'loss': 13.8304, 'grad_norm': 0.5884380340576172, 'learning_rate': 3.3898305084745763e-06, 'epoch': 1.96}
{'train_runtime': 8850.9962, 'train_samples_per_second': 0.442, 'train_steps_per_second': 0.028, 'train_loss': 14.85345543408003, 'epoch': 1.99}
***** train metrics *****
  epoch                    =     1.9888
  total_flos               = 17787661GF
  train_loss               =    14.8535
  train_runtime            = 2:27:30.99
  train_samples_per_second =      0.442
  train_steps_per_second   =      0.028
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 420/420 [10:08<00:00,  1.45s/it]
***** eval metrics *****
  epoch                   =     1.9888
  eval_loss               =     1.7048
  eval_runtime            = 0:10:09.11
  eval_samples_per_second =      1.377
  eval_steps_per_second   =       0.69
